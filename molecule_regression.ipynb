{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Danielle-Grattarola\" data-toc-modified-id=\"Danielle-Grattarola-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Danielle Grattarola</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danielle Grattarola\n",
    "https://github.com/danielegrattarola/spektral/blob/master/examples/graph_prediction/qm9_batch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QM9 dataset.\n",
      "Reading SDF\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mark/.spektral/datasets/qm9/qm9.sdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3673dae1bbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                            \u001b[0mself_loops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                            \u001b[0mauto_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                            amount=1000)  # Set to None to train on whole dataset\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[0;31m# Heat capacity at 298.15K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spektral/datasets/qm9.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(nf_keys, ef_keys, auto_pad, self_loops, amount, return_type)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading QM9 dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msdf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qm9.sdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Internal SDF format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Load labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spektral/utils/io.py\u001b[0m in \u001b[0;36mload_sdf\u001b[0;34m(filename, amount)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m    312\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading SDF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_sdf_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mark/.spektral/datasets/qm9/qm9.sdf'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example shows how to perform regression of molecular properties with the\n",
    "QM9 database, using a simple GNN in disjoint mode.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from spektral.datasets import qm9\n",
    "from spektral.layers import EdgeConditionedConv, ops, GlobalSumPool\n",
    "from spektral.utils import batch_iterator, numpy_to_disjoint\n",
    "from spektral.utils import label_to_one_hot\n",
    "\n",
    "################################################################################\n",
    "# PARAMETERS\n",
    "################################################################################\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 10           # Number of training epochs\n",
    "batch_size = 32       # Batch size\n",
    "\n",
    "################################################################################\n",
    "# LOAD DATA\n",
    "################################################################################\n",
    "A, X, E, y = qm9.load_data(return_type='numpy',\n",
    "                           nf_keys='atomic_num',\n",
    "                           ef_keys='type',\n",
    "                           self_loops=False,\n",
    "                           auto_pad=False,\n",
    "                           amount=1000)  # Set to None to train on whole dataset\n",
    "y = y[['cv']].values  # Heat capacity at 298.15K\n",
    "\n",
    "# Preprocessing\n",
    "X_uniq = np.unique([v for x in X for v in np.unique(x)])\n",
    "E_uniq = np.unique([v for e in E for v in np.unique(e)])\n",
    "X_uniq = X_uniq[X_uniq != 0]\n",
    "E_uniq = E_uniq[E_uniq != 0]\n",
    "\n",
    "X = [label_to_one_hot(x, labels=X_uniq) for x in X]\n",
    "E = [label_to_one_hot(e, labels=E_uniq) for e in E]\n",
    "\n",
    "# Parameters\n",
    "F = X[0].shape[-1]   # Dimension of node features\n",
    "S = E[0].shape[-1]   # Dimension of edge features\n",
    "n_out = y.shape[-1]  # Dimension of the target\n",
    "\n",
    "# Train/test split\n",
    "A_train, A_test, \\\n",
    "X_train, X_test, \\\n",
    "E_train, E_test, \\\n",
    "y_train, y_test = train_test_split(A, X, E, y, test_size=0.1, random_state=0)\n",
    "\n",
    "################################################################################\n",
    "# BUILD MODEL\n",
    "################################################################################\n",
    "X_in = Input(shape=(F,), name='X_in')\n",
    "A_in = Input(shape=(None,), sparse=True, name='A_in')\n",
    "E_in = Input(shape=(S,), name='E_in')\n",
    "I_in = Input(shape=(), name='segment_ids_in', dtype=tf.int32)\n",
    "\n",
    "X_1 = EdgeConditionedConv(32, activation='relu')([X_in, A_in, E_in])\n",
    "X_2 = EdgeConditionedConv(32, activation='relu')([X_1, A_in, E_in])\n",
    "X_3 = GlobalSumPool()([X_2, I_in])\n",
    "output = Dense(n_out)(X_3)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in, E_in, I_in], outputs=output)\n",
    "opt = Adam(lr=learning_rate)\n",
    "loss_fn = MeanSquaredError()\n",
    "\n",
    "\n",
    "@tf.function(\n",
    "    input_signature=(tf.TensorSpec((None, F), dtype=tf.float64),\n",
    "                     tf.SparseTensorSpec((None, None), dtype=tf.float64),\n",
    "                     tf.TensorSpec((None, S), dtype=tf.float64),\n",
    "                     tf.TensorSpec((None,), dtype=tf.int32),\n",
    "                     tf.TensorSpec((None, n_out), dtype=tf.float64)),\n",
    "    experimental_relax_shapes=True)\n",
    "def train_step(X_, A_, E_, I_, y_):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model([X_, A_, E_, I_], training=True)\n",
    "        loss = loss_fn(y_, predictions)\n",
    "        loss += sum(model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# FIT MODEL\n",
    "################################################################################\n",
    "current_batch = 0\n",
    "model_loss = 0\n",
    "batches_in_epoch = np.ceil(len(A_train) / batch_size)\n",
    "\n",
    "print('Fitting model')\n",
    "batches_train = batch_iterator([X_train, A_train, E_train, y_train],\n",
    "                               batch_size=batch_size, epochs=epochs)\n",
    "for b in batches_train:\n",
    "    X_, A_, E_, I_ = numpy_to_disjoint(*b[:-1])\n",
    "    A_ = ops.sp_matrix_to_sp_tensor(A_)\n",
    "    y_ = b[-1]\n",
    "    outs = train_step(X_, A_, E_, I_, y_)\n",
    "\n",
    "    model_loss += outs.numpy()\n",
    "    current_batch += 1\n",
    "    if current_batch == batches_in_epoch:\n",
    "        print('Loss: {}'.format(model_loss / batches_in_epoch))\n",
    "        model_loss = 0\n",
    "        current_batch = 0\n",
    "\n",
    "################################################################################\n",
    "# EVALUATE MODEL\n",
    "################################################################################\n",
    "print('Testing model')\n",
    "model_loss = 0\n",
    "batches_in_epoch = np.ceil(len(A_test) / batch_size)\n",
    "batches_test = batch_iterator([X_test, A_test, E_test, y_test], batch_size=batch_size)\n",
    "for b in batches_test:\n",
    "    X_, A_, E_, I_ = numpy_to_disjoint(*b[:-1])\n",
    "    A_ = ops.sp_matrix_to_sp_tensor(A_)\n",
    "    y_ = b[3]\n",
    "\n",
    "    predictions = model([X_, A_, E_, I_], training=False)\n",
    "    model_loss += loss_fn(y_, predictions)\n",
    "model_loss /= batches_in_epoch\n",
    "print('Done. Test loss: {}'.format(model_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "709.091px",
    "left": "797.103px",
    "top": "53.423px",
    "width": "199.261px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
