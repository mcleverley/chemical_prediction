{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from spektral.datasets import citation\n",
    "from spektral.layers import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = 'cora'\n",
    "A, X, y, train_mask, val_mask, test_mask = citation.load_data('cora')\n",
    "\n",
    "# Parameters\n",
    "channels = 16           # Number of channels in the first layer\n",
    "N = X.shape[0]          # Number of nodes in the graph\n",
    "F = X.shape[1]          # Original size of node features\n",
    "n_classes = y.shape[1]  # Number of classes\n",
    "dropout = 0.5           # Dropout rate for the features\n",
    "l2_reg = 5e-4 / 2       # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 200            # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "fltr = GraphConv.preprocess(A).astype('f4')\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "A, X, y, train_mask, val_mask, test_mask = citation.load_data('cora')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(A),type(X),type(y),type(train_mask),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should i just use pytorch instead?\n",
    "now that i know how label propagation works a little better, should i still start with chemical prediction (given i don't have a background in the topic?) or move to a graph I know a little more about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node citation network. each node is a document, edges are citations (undirected).\n",
    "each node has a binary BoW attribute (1 if word is in text). each node has class label for prediction\n",
    "- transductive learning\n",
    "    - observe all nodes & edges at training time, but only some labels\n",
    "    - goal: predict missing labels\n",
    "        - 'infer topic of unknown paper based on citation links'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "# Keras API & Graph Convolutional layer\n",
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "\n",
    "from spektral.datasets import citation\n",
    "A, X, y, train_mask, val_mask, test_mask = citation.load_data('cora')\n",
    "# Adj_matrix = A, sparse matrix of (n,n) node_num\n",
    "# node features X shape(N,F)\n",
    "# labels y, shape (N, n_classes)\n",
    "N = A.shape[0]\n",
    "F = X.shape[-1]\n",
    "n_classes = y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide multiple inputs, X and A, to GraphConv layers\n",
    "# requires graph & its adj_matrix\n",
    "\n",
    "# dataset is just nodes & edges; keras must consider each node as separate sample\n",
    "# so batch axis is None\n",
    "X_in = Input(shape=(F, ))\n",
    "A_in = Input((N, ), sparse=True)\n",
    "# sampling node attributes = vector, shape(F, )\n",
    "# sampling adj_matrix = vector, shape(N, )\n",
    "\n",
    "X_1 = GraphConv(16, 'relu')([X_in, A_in])\n",
    "# regularize with dropout layer\n",
    "X_1 = Dropout(0.5)(X_1)\n",
    "X_2 = GraphConv(n_classes, 'softmax')([X_1, A_in])\n",
    "\n",
    "model = Model(inputs=[X_in, A_in], outputs=X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1433)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 2708)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 16)           22944       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           graph_conv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_5 (GraphConv)        (None, 7)            119         dropout_2[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# pre-proc adj_matrix to add self loops + scale weights of node's connections based on degree\n",
    "A = GraphConv.preprocess(A).astype('f4') # depends on type of layer\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             weighted_metrics=['acc'])\n",
    "# weighted_metrics is better than metrics for our semi-supervised problem (boolean masks)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "X = X.toarray()\n",
    "A = A.astype('f4')\n",
    "validation_data = ([X, A], y, val_mask)\n",
    "# train\n",
    "# batch_size=N, shuffle=False. default Keras splits data into batches of 32, shuffles at epoch\n",
    "# shuffling our adj_matrix on one axis and not other will disjoint our rows completely\n",
    "# splitting graph into batches (subgraphs) might cause havoc and \"disconnected\" nodes\n",
    "# take all node features at once to avoid this.\n",
    "model.fit([X, A], y,\n",
    "          sample_weight=train_mask,\n",
    "          validation_data=validation_data,\n",
    "          batch_size=N,\n",
    "          shuffle=False,\n",
    "         epochs = 100) # default 10 epochs\n",
    "# train_mask, val_mask for sample_weight\n",
    "# in training, train nodes will have weight of 1, val nodes have weight of 0\n",
    "# in validation, train nodes have weight 0, val nodes have weight 1\n",
    " # so we only have to change the mask to differentiate train/test data\n",
    "    # since the model takes X, A and y for train and val phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 852us/step - loss: 0.6856 - acc: 0.7000\n",
      "Done.\n",
      "Test loss: 0.6856234073638916\n",
      "Test accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "# evaluate, only changing the sample_weight and batch_size like before\n",
    "eval_results = model.evaluate([X, A],\n",
    "                              y,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "709.091px",
    "left": "1584.47px",
    "top": "53.4233px",
    "width": "160.98px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
